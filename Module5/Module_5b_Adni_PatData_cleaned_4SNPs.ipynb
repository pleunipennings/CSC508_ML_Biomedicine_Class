{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pleunipennings/CSC508_ML_Biomedicine_Class/blob/main/Module5/Module_5b_Adni_PatData_cleaned_4SNPs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eypv_1yPXe2X"
      },
      "source": [
        "# Welcome to the notebook where we will include data on 4 SNPs on chromosome 19.\n",
        "\n",
        "This notebook was created at San Francisco State University for the PINC and gSTAR programs by Dr Pleuni Pennings, Lucy Moctezuma Tan and Lorena Benitez Rivera. We acknowledge help from Dr Adegoke Ojewole and Dr Hector Corrada Bravo.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqkxZfVhNycC"
      },
      "source": [
        "## Loading libraries and data from Github repository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F48UupL7Lt5S"
      },
      "source": [
        "# Importing packages for data handling\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# importing packages for making Random Forest Model and evaluating performance\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn import preprocessing\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# importing packages for ploting\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from plotnine import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZvCupM1WwFM"
      },
      "source": [
        "Load the \"PatData_cleaned_4SNPs.csv\" version of the dataset that has only 4 SNP locations on chromosome 19."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XRGmk1gGSxD"
      },
      "source": [
        "# Loading data from github repository\n",
        "url = \"https://raw.githubusercontent.com/pleunipennings/CSC508Data/main/PatData_cleaned_4SNPs.csv\"\n",
        "data = pd.read_csv(url)\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2C9b-UU4pgeC"
      },
      "source": [
        "## Dropping Missing values\n",
        "\n",
        "As mentioned before we have new features we have not used before, we will see if these will help improve our model's predictions for Alzheimers. Below we have a list of column names."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRVK5s1qfShX"
      },
      "source": [
        "# Loading column feature names\n",
        "data.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing data\n",
        "data.isna().sum()"
      ],
      "metadata": {
        "id": "DGDlTTRtEafS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voqOkMiVquJa"
      },
      "source": [
        "#Let's drop missing data present in the location features\n",
        "data = data.dropna()\n",
        "# Check how much data you have left\n",
        "data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploring Genetic Data ( APOE4 and SNPs Data)\n",
        "\n",
        "## APOE4 Data\n",
        "\n",
        "We have work with this mysterious feature before. But it is worth taking a closer look into it. The APOE4 gene has been associated with an increased risk of Alzheimer's disease. APOE4 has values for each patient that range from 0 to 2. We see here that 0 is most common, followed by 1 and then 2. When a patient has a 0 here, it means that the patient doesnâ€™t carry the APOE4 allele, 1 means they carry one copy of APOE4 and 2 means they carry two copies."
      ],
      "metadata": {
        "id": "3r9I3ajkLRZv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 1: plotting APOE4 frequencies.\n",
        "\n",
        "- Create a barplot to check what percentage of people in this dataset carry both copies of this gene!"
      ],
      "metadata": {
        "id": "Ycct305OBT9h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# input your code here"
      ],
      "metadata": {
        "id": "zlOc58plzQYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SNP Locations Data\n",
        "\n",
        "Recall from the text that **SNP (Single Nucleotide Polymorphism)** are variants that consist of just one nucleotide in the same location. For our dataset we are considering 4 locations. These are:\n",
        "\n",
        "- **rs4147929**\n",
        "- **rs41289512**\n",
        "- **rs76320948**\n",
        "- **rs3865444**\n",
        "\n",
        "These variables represent the location of SNP (snips) that we have interest in, essentially it is the equivalent of a genetic address. These are official names you can google to find more about each of these sites.\n",
        "\n",
        "Normally, for each SNP, each chromosome can carry one genetic letter (A, C, G or T). Because we each have two copies of each of our chromosomes, we also have two letters for a SNP.\n",
        "\n",
        "On a website called SNPedia, I looked up rs4147929. It tells me that we can have AA, AG or GG at this location. Carrying one or two A's at this location is associated with higher Alzheimer's risk.\n",
        "\n",
        "Now, in the data we have, the letters are not listed, but instead a number is listed that we can interpret as the estimated number of G (non-risk) alleles in that person. If this number is close to 2, the person has genotype GG, if the number is close to 1, they have AG and if the number is close to 0, they have the AA genotype.\n",
        "\n",
        "The reason that the numbers are not exactly 0, 1, and 2 has to do with how the data is collected.\n",
        "\n",
        "https://www.snpedia.com/index.php/Rs4147929\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JYNsaLvKEOj6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Looking at values in location \"rs4147929\"\n",
        "\n",
        "data[\"rs4147929\"].value_counts()"
      ],
      "metadata": {
        "id": "wdaN5DPL-Nx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's round to have no decimals.\n",
        "data[\"rs4147929\"] = data[\"rs4147929\"].round(decimals = 0)"
      ],
      "metadata": {
        "id": "GkV6zp8sUsG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"rs4147929\"].value_counts()"
      ],
      "metadata": {
        "id": "4fg3OXR0U2V1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below is some terminoly for those who are not familiar with Genetic jargon!\n",
        "\n",
        "- **Minor Frequency Alleles (MAF):** is the frequency at which the second most common allele in a population occur. They are important to study in population genetics because they provide information to distinguish comon versus rare variants in a population.\n",
        "\n",
        "- **Homozygotes:**\n",
        "The SNPs Minor Frequency Alleles are taken from Table 1 in this [paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6836675/).\n",
        "Each SNP comes in two letters (two alleles). The one that is less common is called the minor allele.\n",
        "\n",
        "Note that for this SNP in location **rs4147929**, the Minor Allele Frequency is listed as 0.161. We therefore expect the square of that frequency to be the number of people who carry the allele 2x (homozygotes). In other words: if around 16% of all chromosome 19s in humans have an A at this location, then the chance that someone has two As is 16% of 16% = 2.6%. In our dataset, that would translate to just 18 people out of 698 people. Is this actually what the data shows?\n",
        "\n",
        "$698* (0.161^2) = 18 \\ people$.\n",
        "\n",
        "As you can see in one of the previous cells, we have 21 peope in the dataset with two times the minor allele. That is pretty close to 18!"
      ],
      "metadata": {
        "id": "Zr3ROxv7-PBh"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYesLoZ4c4qO"
      },
      "source": [
        "# Plotting counts for location rs4147929\n",
        "(ggplot(data=data) +\n",
        " aes(x='rs4147929') +\n",
        " geom_histogram(stat='bin', binwidth = 0.1) +\n",
        " labs(x = \"rs4147929\")\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now for this SNP in location **rs41289512** the Minor Allele Frequency (MAF) listed was 0.039. Notice that there are no homozygotes of the second type. We would expect $0.039^2 \\ homozygotes = 0.15%$ . Out of 698 patients, we had expected just 1 patient with two times the minor allele. It is not so surprising that we don't see any."
      ],
      "metadata": {
        "id": "_QcDXsGk538I"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiFDvDrcoTWP"
      },
      "source": [
        "# Plotting counts for location rs41289512\n",
        "(ggplot(data=data) +\n",
        " aes(x='rs41289512') +\n",
        " geom_histogram(stat='bin', binwidth = 0.1) +\n",
        " labs(x = \"rs41289512\")\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 2: Looking at SNP genotypes.\n",
        "\n",
        "- Plot the frequency barplots for the other two sites (**rs76320948** and **rs3865444**).\n",
        "- Calculate the expected and observed number of people in the dataset with twice the minor allele for these SNPs. Is it what was expected?\n"
      ],
      "metadata": {
        "id": "R_uYGCkiCx5v"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpljglairYec"
      },
      "source": [
        "# Input your code here for site rs76320948\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input your code here for site rs3865444"
      ],
      "metadata": {
        "id": "9TXDcbj4DfO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpKfJnBqwoce"
      },
      "source": [
        "# Random forest with genetic data for 4 SNPs\n",
        "\n",
        "In this part we will create a Random Forest Model from this data set and valuate the model.\n",
        "\n",
        "- Split the data in labels (the diagnosis) and features (the other columns)\n",
        "- Use about 70-80% of our data as the training data and the rest as test data. In the code, 70% training and 30% test.\n",
        "- Create our Randdom Fores model and training it\n",
        "- Making our predictions\n",
        "\n",
        "**NOTE:** Notice that we have set the *Random seed = 1* for splitting our data and into testing and when creating our Random Forest object. This was done for reproducibility of results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7KzBd9bit-2"
      },
      "source": [
        "# Splitting data into labels and features\n",
        "labels = data[\"DX\"]\n",
        "features = data.drop(columns=['PTID','DX'])\n",
        "\n",
        "# splitting data into training and testing sets\n",
        "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.3, random_state=1)\n",
        "\n",
        "# creating Random Fores Model and Training it\n",
        "rf = RandomForestClassifier(n_estimators = 1000, bootstrap = True, random_state = 1)\n",
        "rf.fit(features_train, labels_train)\n",
        "\n",
        "# #Predict the response for test dataset\n",
        "labels_pred = rf.predict(features_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now take a look at what was predicted and have a sense of how we did by creating a Confusion Matrix Plot. We can also plot an accuracy score along with it."
      ],
      "metadata": {
        "id": "tozRJAytFnOY"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPd3df_Li5uV"
      },
      "source": [
        "# Look at the predicted values.\n",
        "print(labels_pred[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nK-pU-gG1AH0"
      },
      "source": [
        "#Let's visualize how well the RF does.\n",
        "accuracy = accuracy_score(labels_test, labels_pred)\n",
        "print(\"Accuracy: %.1f%%\" % (accuracy * 100))\n",
        "plt2 = metrics.ConfusionMatrixDisplay.from_estimator(rf, features_test, labels_test)\n",
        "plt.grid(False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that our model seems to predict fairly well for people that have Alzheimer's, 14 mistakes versus 59 correct predictions. For Mild Cognitive impairment the model does not do as well with 43 correct predictions versus 38 erros and finally for Normal is doesn't do well at all since its 20 versus 36.\n",
        "\n",
        "We can actually obtain individual measures for how well a model does for a particular class using **F-scores**, more on this in later modules.\n"
      ],
      "metadata": {
        "id": "paL9vy-NHiQk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Checking Feature Importance for our model\n",
        "\n",
        "Below we will check the feature importance for our model. Recall that this basically shows us what features were most relevant in making predictions. Let's also visualize this to see where does SNP features rank in terms of importance for the model."
      ],
      "metadata": {
        "id": "_X50OSyZJY4Z"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdsCNF6N1k4Z"
      },
      "source": [
        "# getting feature importance values from our model\n",
        "importance = rf.feature_importances_\n",
        "\n",
        "# summarize feature importance / see if the SNP columns are important for the RF\n",
        "names = features.columns.to_numpy(dtype=object)\n",
        "\n",
        "# Creating a dataframe for feature importance\n",
        "importanceDF = pd.DataFrame({'names':names, 'importance':importance})\n",
        "\n",
        "# Sort the dataframe with feature importances\n",
        "importanceDF = importanceDF.sort_values(by=['importance'])\n",
        "\n",
        "# Creating barplot for feature importance\n",
        "importanceDF.plot.barh(x='names', y='importance', figsize = (10,10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The SNP locations do not place very high in terms of aiding prediction for our model. We can see that the presence of the gene APOE4 is more relevant! The main important feature still is the hypocampus volume though by far.\n",
        "\n",
        "So the question remains if adding genetic data actually help with the predictions at all? Below we will redo the Random Forest Model this time without the genetic data to see changes in the performance of the model and find out!"
      ],
      "metadata": {
        "id": "LqnUUi5vKS5K"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oF2TBpMg6c36"
      },
      "source": [
        "# Does Removing Genetic Data worsen the results for Random Forest Model?\n",
        "\n",
        "In this iteration we will refit our model twice:\n",
        "\n",
        "- First by removing the SNP location data **Model 1**\n",
        "\n",
        "- Then by removing both SNP location data as well as the APOE4 gene feature **Model 2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2Tf-qoA2kNK"
      },
      "source": [
        "# Creating  2 lists of column features one with just SNP sites and another with all genetic data\n",
        "SNP_cols = ['rs4147929', 'rs41289512', 'rs76320948', 'rs3865444']\n",
        "Genetics_cols = ['rs4147929', 'rs41289512', 'rs76320948', 'rs3865444', 'APOE4']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will create 2 sets of features for both our models as described above. Our labels are still the same as before so we don't need to redefine them here."
      ],
      "metadata": {
        "id": "i9VxZw0bOggr"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Erud0nH_vHM5"
      },
      "source": [
        "# Features for model 1\n",
        "features_no_snp = features[features.columns.drop(SNP_cols)]\n",
        "\n",
        "# Features for model 2\n",
        "features_no_genetics = features[features.columns.drop(Genetics_cols)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will proceed with doing 2 different splits of training and testing data. Notice that i am keeping the random seed as 1 just to be consistent with the prior model containing all genetic features."
      ],
      "metadata": {
        "id": "MtYwQ6SYPR2D"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dOyrBQQv94m"
      },
      "source": [
        "# Split of testing and training for Model 1\n",
        "X_train1, X_test1, Y_train1, Y_test1 = train_test_split(features_no_snp, labels, test_size=0.3, random_state=1)\n",
        "\n",
        "# Split of testing and training for Model 2\n",
        "X_train2, X_test2, Y_train2, Y_test2 = train_test_split(features_no_genetics, labels, test_size=0.3, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will be creating 2 random forest models and train them separately. We have mantain again the same hyperparameter settings than before so we can make a fairer comparison."
      ],
      "metadata": {
        "id": "nRT2oqVIRELj"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIwS98j4wGhi"
      },
      "source": [
        "# Creating and training Random forest with model 1\n",
        "rf1 = RandomForestClassifier(n_estimators = 1000, bootstrap = True, random_state = 1)\n",
        "rf1.fit(X_train1, Y_train1)\n",
        "\n",
        "# Creating and training Random forest with model 2\n",
        "rf2 = RandomForestClassifier(n_estimators = 1000, bootstrap = True, random_state = 1)\n",
        "rf2.fit(X_train2, Y_train2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will make 2 sets of predictions, one with model1 and another with model2"
      ],
      "metadata": {
        "id": "1g1mfB_oSrkq"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhEdHobbwVxV"
      },
      "source": [
        "# Predictions using model 1\n",
        "Y_pred1 = rf1.predict(X_test1)\n",
        "\n",
        "# Predictions using model 2\n",
        "Y_pred2 = rf2.predict(X_test2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally we will be taking a look at each models confusion matrix and accuracy scores, and what differences we get if any!"
      ],
      "metadata": {
        "id": "hjeIKSoyTJ5I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plot for model 1\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 10), sharey= True)\n",
        "rf1_matrix = confusion_matrix(Y_test1, Y_pred1)\n",
        "plt1 = ConfusionMatrixDisplay(rf1_matrix, display_labels=[\"Dementia\",\"MCI\",\"NL\"])\n",
        "plt1.plot(ax=ax1)\n",
        "plt1.ax_.set_title(\"Model 1: No SNP Location data\")\n",
        "plt1.im_.colorbar.remove()\n",
        "\n",
        "# plot for Model 2\n",
        "rf2_matrix = confusion_matrix(Y_test2, Y_pred2)\n",
        "plt2 = ConfusionMatrixDisplay(rf2_matrix, display_labels=[\"Dementia\",\"MCI\",\"NL\"])\n",
        "plt2.plot(ax=ax2)\n",
        "plt2.ax_.set_title(\"Model 2: No SNP Location & APOE4 data\")\n",
        "plt2.im_.colorbar.remove()\n",
        "\n",
        "plt.grid(False)\n"
      ],
      "metadata": {
        "id": "glAHu1MDWUSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Q3Mv7fhwOYO"
      },
      "source": [
        "# printing accuracies for both models\n",
        "acc_1 = accuracy_score(Y_test1, Y_pred1)\n",
        "print(\"Accuracy for model 1: %.1f%%\" % (acc_1 * 100))\n",
        "acc_2 = accuracy_score(Y_test2, Y_pred2)\n",
        "print(\"Accuracy for model 2: %.1f%%\" % (acc_2 * 100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking at both of these Confusion matrices side by side, it looks like they are not that different. Model 2 does not include APOE4 and it seemed to only do a bit worse than Model 1. Surprisingly however removing the genetic information seems to have increased it's accuracy, albeit just by a minuscule amount!"
      ],
      "metadata": {
        "id": "96mAwOsFldpu"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrHbbUmA4JwC"
      },
      "source": [
        "# How will a Gradient Boosted Tree Model do?\n",
        "\n",
        "Below we can quickly check the accuracies had we tried using a Gradient Boosted Model rather than a Random Forest. We will do a check of accuracies for 3 models:\n",
        "\n",
        "- Including all the original data **Model GBT**\n",
        "\n",
        "- First by removing the SNP location data **Model GBT1**\n",
        "\n",
        "- Then by removing both SNP location data as well as the APOE4 gene feature **Model GBT2**\n",
        "\n",
        "Recall that first we need to recode our labels into numbers for XGBoost modeling before we split the data. In the code below we will transform our Diagnosis Category into the values 0, 1 and 2 (Dementia, MCI and NL)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separating labels from the general dataframe\n",
        "labels = data[\"DX\"]\n",
        "# Creating a label encoder object\n",
        "le = preprocessing.LabelEncoder()\n",
        "# Fitting the label encoder into the labels columns\n",
        "le.fit(data[\"DX\"])\n",
        "# Transforming the classes into numbers\n",
        "labels_t = le.transform(data[\"DX\"])"
      ],
      "metadata": {
        "id": "Qhwnr3hDovlN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting the Data again after **recoding the label** into numbers."
      ],
      "metadata": {
        "id": "uIXS9Q_AtnI-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split of testing and training for Model GBT\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(features, labels_t, test_size=0.3, random_state=1)\n",
        "\n",
        "# Split of testing and training for Model GBT1\n",
        "X_train1, X_test1, Y_train1, Y_test1 = train_test_split(features_no_snp, labels_t, test_size=0.3, random_state=1)\n",
        "\n",
        "# Split of testing and training for Model GBT2\n",
        "X_train2, X_test2, Y_train2, Y_test2 = train_test_split(features_no_genetics, labels_t, test_size=0.3, random_state=1)"
      ],
      "metadata": {
        "id": "Fbr9r2CrqbFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can quickly run **Model GBT**, **Model GBT1** and **Model GBT2** to compare accuracies."
      ],
      "metadata": {
        "id": "haz33SNJprs1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking accuracy for Model GBT\n",
        "GBT = XGBClassifier(random_state=1)\n",
        "GBT.fit(X_train, Y_train)\n",
        "Y_pred_GBT = GBT.predict(X_test)\n",
        "acc_GBT = accuracy_score(Y_test, Y_pred_GBT)\n",
        "print(\"Accuracy: %.1f%%\" % (acc_GBT * 100))"
      ],
      "metadata": {
        "id": "9fHrARM2nZS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4YRE76GxaGe"
      },
      "source": [
        "# Checking accuracy for Model GBT1\n",
        "GBT1 = XGBClassifier()\n",
        "GBT1.fit(X_train1,Y_train1)\n",
        "Y_pred_GBT1 = GBT1.predict(X_test1)\n",
        "acc_GBT1 = accuracy_score(Y_test1, Y_pred_GBT1)\n",
        "print(\"Accuracy: %.1f%%\" % (acc_GBT1 * 100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ds0zGR2lyS2u"
      },
      "source": [
        "# Checking accuracy for Model GBT2\n",
        "GBT2 = XGBClassifier()\n",
        "GBT2.fit(X_train2,Y_train2)\n",
        "Y_pred_GBT2 = GBT2.predict(X_test2)\n",
        "acc_GBT2 = accuracy_score(Y_test2, Y_pred_GBT2)\n",
        "print(\"Accuracy: %.1f%%\" % (acc_GBT2 * 100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Overall It seems that Gradient Boosted Trees perform better than the Random Forest one. However, it seems that for Gradient Boosted Trees, including less Genetic data seems to worsen the performance, unlike what we saw for Random Forests."
      ],
      "metadata": {
        "id": "qyUALKZIs2M7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rX3uwfM_fUS"
      },
      "source": [
        "## Task 3: Hyperparameters.\n",
        "1. Go back to the results of your hyper parameter tuning work. Plug in some better parameters in the models I made above. Can you make them perform better?\n",
        "2. Does the genetic information about the patients help us make a better predictive model?"
      ]
    }
  ]
}
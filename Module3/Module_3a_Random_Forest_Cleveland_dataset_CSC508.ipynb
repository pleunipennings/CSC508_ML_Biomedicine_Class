{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pleunipennings/CSC508_ML_Biomedicine_Class/blob/main/Module3/Module_3a_Random_Forest_Cleveland_dataset_CSC508.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7WqFNeW_z3y"
      },
      "source": [
        "## **Welcome to the module 3a coding part: Random Forest!**\n",
        "\n",
        "*This notebook was originally created at San Francisco State University (SFSU) by Vaisakh Kusabhadran, Amisha Dhawan, Yuomi Zavaleta (all SFSU students) and Pleuni Pennings (SFSU bio professor).*\n",
        "\n",
        "*This notebook was edited for the Promoting INclusivity and Computing (PINC) and gSTAR programs by Dr. Pleuni Pennings, Lucy Moctezuma Tan and Lorena Benitez-Rivera (master students) all members of the COde to understand Drug resistance Evolution (CODE) lab at SFSU in 2023.*"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#OBJECTIVE OF THIS NOTEBOOK:\n",
        "\n",
        "In this notebook we will revisit the Cleaveland heart disease dataset, this time we will use a **Random Forest** to make our predictions rather than just using a single Decision Tree. Below is a summary of the variables that this dataset contains.\n",
        "\n",
        "<ul type = \"square\">\n",
        "<li> [1] #3 Age: age in years</li>\n",
        "<li> [2] #4 Sex: sex (1 = male; 0 = female)</li>\n",
        "<li> [3] #9 Chest_pain_type\n",
        "<ul>\n",
        "<li>Value 1: typical angina\n",
        "<li>Value 2: atypical angina\n",
        "<li>Value 3: non-anginal pain\n",
        "<li>Value 4: asymptomatic</li>\n",
        "</ul>\n",
        "<li> [4] #10 At_rest_bp: resting blood pressure (in mm Hg on admission to the hospital)</li>\n",
        "<li> [5] #12 Cholesterol: serum cholestoral in mg/dl </li>\n",
        "<li> [6] #16 Fast_blood_sug: (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false)</li>\n",
        "<li> [7] #19 Rest_ecg: resting electrocardiographic results\n",
        "<ul>\n",
        "<li>Value 0: normal\n",
        "<li>Value 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV)\n",
        "<li>Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria</li>\n",
        "</ul>\n",
        "<li> [8] #32 Maxhr: thalach: maximum heart rate achieved</li>\n",
        "<li> [9] #38 Exer_angina: exang: exercise induced angina (1 = yes; 0 = no)</li>\n",
        "<li> [10] #40 Oldpeak: ST depression induced by exercise relative to rest </li>\n",
        "<li> [11] #41 Slope: the slope of the peak exercise ST segment\n",
        "<ul>\n",
        "<li> Value 1: upsloping</li>\n",
        "<li> Value 2: flat</li>\n",
        "<li> Value 3: downsloping</li>\n",
        "</ul>\n",
        "<li> [12] #44 Ca: number of major vessels (0-3) colored by flourosopy</li>\n",
        "<li> [13] #51 Thal: Thallium or stress test 3 = normal; 6 = fixed defect; 7 = reversable defect. See this\n",
        "<a href=\"https://www.healthline.com/health/thallium-stress-test\">website</a>\n",
        "for more info on the thallium or stress test.\n",
        "</li>\n",
        "<li> [14] #58 Diag: num: diagnosis of heart disease (angiographic disease status)\n",
        "<ul>\n",
        "<li>Value 0: no vessel with 50% diameter narrowing</li>\n",
        "<li>Value 1: one vessel with 50% diameter narrowing</li>\n",
        "<li>Value 2,3,4: 2,3,4 vessels with 50% diameter narrowing</li>\n",
        "</ul>\n",
        "</li>\n",
        "</ul>\n",
        "\n",
        "The **goal** of this notebook is to work with a random forest model.\n",
        "\n",
        "Your mission is to run each cell, see what happens, and answer some questions based on the code.\n",
        "\n",
        "# Let's look at the Cleveland dataset again using a **Random Forest model**."
      ],
      "metadata": {
        "id": "w8mECq8USHsd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#WHAT ARE RANDOM FOREST?\n",
        "\n",
        "In this notebook you will make a random forest. A random forest is a collection of random-ish decision trees. This model essentially combines the output of multiple decision trees to reach a particular prediction. Most jargon in Machine Learning is just ugly, imo. But Random Forest sounds nice to me, a little poetic. If I were a singer-songwriter, I could imagine titling my album after random forests.  \n",
        "\n",
        "![PleunismusicAlbum.png](https://drive.google.com/uc?export=view&id=1-CtmRWaxAVuq8twD_rx6-qxS2kUJ1z0U)\n",
        "\n",
        "You can find more information about Random Forest here: [Scikit-learn: Random Forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)"
      ],
      "metadata": {
        "id": "-_PIWEAUN64B"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cImVL7v-FJAn"
      },
      "source": [
        "### **Task 1:** Exploring the data (Questions 1-4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9E3Qi2A-gc3"
      },
      "source": [
        "##**Step 1) Preparing packages**\n",
        "\n",
        "Importing all the necessary packages needed for processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1v9MGH25h_K"
      },
      "source": [
        "# Importing packages that deal with Data manipulation and visualization\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# importing libraries for ML model\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import tree\n",
        "\n",
        "# packages for plotting\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import graphviz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfHd_SKo-9oy"
      },
      "source": [
        "##**Step 2) Importing Cleveland dataset**\n",
        "\n",
        "Reading the dataset from the github repository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6xyLXa-4sBA"
      },
      "source": [
        "# Loading Data from Class github\n",
        "columns = [\"Age\",\"Sex\",\"Chest_pain_type\",\"At_rest_bp\",\"Cholesterol\",\"Fast_blood_sug\",\"Rest_ecg\",\"Maxhr\",\"Exer_angina\",\"Oldpeak\",\"Slope\",\"Ca\",\"Thal\",\"Diag\"]\n",
        "cleveland_data = pd.read_csv('https://raw.githubusercontent.com/pleunipennings/CSC508Data/main/processed.cleveland.data.txt',header=None,names=columns )\n",
        "\n",
        "cleveland_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1S_Tos3_z0G"
      },
      "source": [
        "##**Step 3) Dealing with missing data**\n",
        "\n",
        "Replacing '?' in the dataset with the median value for that column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqUVxOto5g9J"
      },
      "source": [
        "# dealing with missing values\n",
        "cleveland_data = cleveland_data.replace('?', np.nan)\n",
        "\n",
        "# Convert 'Thal' and 'Ca' columns to numeric before calculating the median\n",
        "cleveland_data['Thal'] = pd.to_numeric(cleveland_data['Thal'])\n",
        "cleveland_data['Ca'] = pd.to_numeric(cleveland_data['Ca'])\n",
        "\n",
        "# Replace with median\n",
        "cleveland_data['Thal'] = cleveland_data['Thal'].fillna(cleveland_data['Thal'].median())\n",
        "cleveland_data['Ca'] = cleveland_data['Ca'].fillna(cleveland_data['Ca'].median())\n",
        "\n",
        "# checking number of missing values afterwards\n",
        "(cleveland_data==np.nan).sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMXdqdNu5VvU"
      },
      "source": [
        "# Checking the dimensions of the dataset\n",
        "print(\"The dimension of the table is:\",cleveland_data.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIgKTDmC_sBj"
      },
      "source": [
        "##**Step 4) Splitting target and features**\n",
        "\n",
        "Separating out the target (label) which is what we want to predict, the \"Diag\" column from the rest of the dataset (the features).\n",
        "\n",
        "Converting the labels to binary values so that the model is trained just to predict the presence/absence of heart disease."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPtNNPXz7pl4"
      },
      "source": [
        "# Converting the label into a binary variable\n",
        "labels = np.array(cleveland_data[\"Diag\"])\n",
        "labels = np.where(labels >= 1,1,0)\n",
        "labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjXOO07mc4tZ"
      },
      "source": [
        "###**Question 1:**\n",
        "\n",
        "What does 0 and 1 represent in this array?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rrm0eWoc4tx"
      },
      "source": [
        "**Question 1 answer:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5L7VEtlnABm0"
      },
      "source": [
        "Dropping the label from the dataset. Now since the label has got removed, we can use this dataset to train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ggouqQh8JMx"
      },
      "source": [
        "# Isolating the features Dataset\n",
        "features = cleveland_data.drop(columns='Diag')\n",
        "features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eokVKD5-b-CK"
      },
      "source": [
        "###**Question 2:**\n",
        "\n",
        "What do you think it could happen if we don't drop the target or the label column?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFbsT1VUb-Ck"
      },
      "source": [
        "**Question 2 answer:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Op16ZEnDATcg"
      },
      "source": [
        "Converting the dataframe into an Numpy array as the algorithm requires a Numpy array for processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jj-yNr3D8XKh"
      },
      "source": [
        "# Converting the features dataset into an array\n",
        "features_arr = np.array(features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ct6PZxP1Bk96"
      },
      "source": [
        "##**Step 5) Separating train and test data**\n",
        "\n",
        "* **test_size = 0.25** Gives the propotion of the dataset to include in the test set. 0.25 represents 25%. <br>\n",
        "* **random_state = 1** Random state ensures that the splits that you generate are reproducible.\n",
        "\n",
        "Scikit-learn uses random permutations to generate the splits. The random state that you provide is used as a seed to the random number generator. This ensures that the random numbers are generated in the same order. More details - [Scikit-learn: Random numbers](https://scikit-learn.org/stable/glossary.html#term-random_state)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEBtKmLsaZxC"
      },
      "source": [
        "###**Question 3:**\n",
        "\n",
        "For the decision tree model, we used random_state = 2. Here we are using 1 only, do you think that would make a big difference, why or why not?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Wgy5iqaaZxg"
      },
      "source": [
        "**Question 3 answer:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKD1uq-e8ZAO"
      },
      "source": [
        "# Making 4 groups for training and testing purposes\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(features_arr, labels, test_size = 0.25, random_state = 42)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Question 4:**\n",
        "\n",
        "What percentage of the data is used for training?"
      ],
      "metadata": {
        "id": "1pH30R86EuBZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 4 answer:**"
      ],
      "metadata": {
        "id": "YCD_BP2OFgmq"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJZJlOZuFP_F"
      },
      "source": [
        "# looking at the training data labels\n",
        "print(\"Number of people without Heart Disease: \",np.bincount(train_labels)[0])\n",
        "print(\"Number of people with Heart Disease: \",np.bincount(train_labels)[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6beACalEHUl1"
      },
      "source": [
        "# looking at the testing data labels\n",
        "print(\"Number of people without Heart Disease: \",np.bincount(test_labels)[0])\n",
        "print(\"Number of people with Heart Disease: \",np.bincount(test_labels)[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task 2:** Undestanding the Random Forest model (Questions 5-7)"
      ],
      "metadata": {
        "id": "Nfsqd74eelhM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vW8GlfhJS_fu"
      },
      "source": [
        "###**Question 5:**\n",
        "\n",
        "Do some google search, what is the difference between random forest classifier and random forest regressor, which one is the most used?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYHItZEPTah7"
      },
      "source": [
        "**Question 5 answer:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTaNYbH6ZV5h"
      },
      "source": [
        "###**Question 6:**\n",
        "\n",
        "In this notebook, are we using random forest classifier or random forest regressor, how do you know?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbrTowSlZV6A"
      },
      "source": [
        "**Question 6 answer:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lU5rlOYuB3-J"
      },
      "source": [
        "## **Step 6) Making the random forest tree and making predictions with it**\n",
        "\n",
        "Training the model using test set.\n",
        "You will see here that actually training the model is super easy and fast.\n",
        "\n",
        "We just need to decide how many random trees we'll make, we use:\n",
        "\n",
        "**random state = 42** so that we can all get exactly the same results, but if you change the random state, you'll get slightly different results. It's called random for a reason!  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cutyhw1V8cD8"
      },
      "source": [
        "# Create and fit Random Forest Trees\n",
        "rf = RandomForestClassifier(n_estimators = 1000, max_features = 'sqrt', bootstrap = True, random_state = 42)\n",
        "rf.fit(train_features, train_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are **1000 trees** that have been created in the code above, This means that we can actually checkout a single decision tree. Since python starts counts from 0. In the code below try changing the index to any value from [0, 999] so that you can see exactly how each of the decision tree looks like!\n",
        "\n",
        "### **Question 7**  \n",
        "Try using index [1] and then index [2] in the code below. You can change the index in the first argument of the function tree.export_graphiz(rf.estimators_[index]). Are the root nodes different for these trees? Why do you think the root nodes are different for those trees?\n"
      ],
      "metadata": {
        "id": "twlaK_rwJ_8Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 7 answer:**"
      ],
      "metadata": {
        "id": "48Vy7QIKsExz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# looking at a single Decision tree inside the random forest\n",
        "single_tree = tree.export_graphviz(rf.estimators_[1], out_file=None,\n",
        "                                  feature_names=features.columns,\n",
        "                                  filled=True, rounded=True,\n",
        "                                  special_characters=True,\n",
        "                                  max_depth= 3)\n",
        "graph = graphviz.Source(single_tree)\n",
        "graph.render(\"Classification tree\")\n",
        "display(graph)"
      ],
      "metadata": {
        "id": "07tOojCBmoX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDnRMiOUCzDE"
      },
      "source": [
        "## **Step 7) Looking at the results and looking at the accuracy of the model**\n",
        "\n",
        "Now that we have seen that our random forest is made out of many trees! lets look at how our random forest chooses its final prediction based on this fact. The code below uses a single row (the second row) from our test data and runs it through each of the trees of our forest."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Code below shows the number of trees that predicted one of the two outcomes\n",
        "votes_for_healthy = 0 #we start with 0 trees \"voting\" for healthy\n",
        "votes_for_heart_disease = 0 #and 0 trees \"voting\" for heart-disease\n",
        "for i in range(0,len(rf)): #loop over each of the trees in the random forest\n",
        "  pred = rf.estimators_[i].predict(test_features[[1]]) #get a prediction from one tree\n",
        "  if pred == 1.00: #if the prediction is \"1\" that's a vote for heart disease\n",
        "    votes_for_heart_disease = votes_for_heart_disease + 1\n",
        "  else: #if the prediction is \"0\" that's a vote for healthy\n",
        "    votes_for_healthy = votes_for_healthy + 1\n",
        "\n",
        "print(\"Number of trees that predicted Healthy: \",votes_for_healthy)\n",
        "print(\"Number of trees that predicted Heart Disease: \",votes_for_heart_disease)"
      ],
      "metadata": {
        "id": "82yxgctLtQUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the fact that most of our trees have chosen **\"Heart Disease\" [1]** over **\"Healthy\" [0]**, what do you think our random forest would predict? Let's see what our random forest would predict for the second row of our test data."
      ],
      "metadata": {
        "id": "py9_b0TpyXyR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction using the second value of our test features\n",
        "pred = rf.predict(test_features[[1]])\n",
        "print(\"Prediction by the entire random forest: \", pred)"
      ],
      "metadata": {
        "id": "idP5SIkJwr-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have seen a bit under the hood of how our random forest makes it's final prediction, let's make all our predictions for all our test data to see the accuracy of our model."
      ],
      "metadata": {
        "id": "qevVMlQUzNi6"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_8DefHs9fMz"
      },
      "source": [
        "# Predictions made for all the test data features\n",
        "predictions = rf.predict(test_features)\n",
        "predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQ32NIYq7Gsi"
      },
      "source": [
        "We use the confusion matrix to visualize how well our model did."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task 3:** Testing accuracy (Questions 8-11)"
      ],
      "metadata": {
        "id": "KAuMbwEhlFVo"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjHCZ53ZUQCj"
      },
      "source": [
        "# Creating a Confusion matrix for our results\n",
        "sns.set(rc={'figure.figsize':(8.7,6.27)})\n",
        "print(metrics.confusion_matrix(test_labels, predictions))\n",
        "plt1 = metrics.ConfusionMatrixDisplay.from_estimator(rf, test_features, test_labels)\n",
        "plt.grid(visible=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HA3o1ovMnsBj"
      },
      "source": [
        "### **Question 8**\n",
        "\n",
        "What did you get for: True Positive (TP), True Negative (TN), False Positive (FP) and False Negative (FN)?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 8 answer:**"
      ],
      "metadata": {
        "id": "08FBzdt2nsB0"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1lQ7eYX93zp"
      },
      "source": [
        "# calculating the accuracy\n",
        "acc = round(100*metrics.accuracy_score(predictions, test_labels),2)\n",
        "print(\"Accuracy:\",acc,\"%\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ES_CXJAZ_mBP"
      },
      "source": [
        "### **Question 9**\n",
        "\n",
        "How does the accuracy of the random forest classifier compare to the decision tree?\n",
        "If you only made 2 random trees in your random forest, would that change your accuracy? Try it out and report here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1tb730HITjgx"
      },
      "outputs": [],
      "source": [
        "#Code line to answer question 9"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 9 answer:**"
      ],
      "metadata": {
        "id": "zwxnDUu8ggCt"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uT9XyTDll40o"
      },
      "source": [
        "### **Question 10**\n",
        "\n",
        "How does the accuracy of the random forest classifier compare to the decision tree?\n",
        "If you only made 4 random trees in your random forest, would that change your accuracy? Try it out and report here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eLUSmQN1l40r"
      },
      "outputs": [],
      "source": [
        "#Code line to answer question 10"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 10 answer:**"
      ],
      "metadata": {
        "id": "EZ0z5qIFl40r"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sz93qDCel5Jc"
      },
      "source": [
        "### **Question 11**\n",
        "\n",
        "How does the accuracy of the random forest classifier compare to the decision tree?\n",
        "If you only made 10 random trees in your random forest, would that change your accuracy? Try it out and report here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fzuwt9all5Jd"
      },
      "outputs": [],
      "source": [
        "#Code line to answer question 11"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 11 answer:**"
      ],
      "metadata": {
        "id": "lcRHsjUql5Jd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task 4:** Visualizing features importance and final thoughts (Questions 12-14)"
      ],
      "metadata": {
        "id": "8pnDsQjljihI"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gK53ZSeU-_1D"
      },
      "source": [
        "## Feature importance\n",
        "\n",
        "Visualizing your results is always an important part of any data science project. Now that we have a random forest based on 1000 random trees, we cannot easily visualize all the trees at once like we did for the decision tree, because it would be an overwhelming set of diagrams. But we can visualize the feature importance. I've seen this kind of plot in published articles. I like it because it helps us understand which features are most important for making predictions.\n",
        "\n",
        "Feature importance is a measurement of how each feature decreases the amount of impurity **(Gini index)** in a node, weighted by the probability of reaching that node. The higher the value the more important the feature. This is usually calculated for each tree in the random forest and then averaged over the total number of trees. The graph below shows these averages.\n",
        "\n",
        "[This blog has a fairly good explanation](https://www.analyticsvidhya.com/blog/2021/10/an-introduction-to-random-forest-algorithm-for-beginners/#:~:text=To%20calculate%20feature%20importance%20using,the%20average%20of%20these%20numbers.)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-WsdlpT99H_"
      },
      "source": [
        "importance = rf.feature_importances_\n",
        "# summarize feature importance\n",
        "print(importance)\n",
        "from matplotlib import pyplot\n",
        "pyplot.barh([x for x in range(len(importance))], importance, tick_label = columns[:-1], )\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45gB467qojnX"
      },
      "source": [
        "### **Question 12**\n",
        "\n",
        "Which are the three features (variables) with the highest importance?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 12 answer:**\n",
        "\n",
        "1.   List item\n",
        "2.   List item\n",
        "3.   List item\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WF4ep72kojno"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Question 13**\n",
        "Do the features that were important in the decision tree we made earlier have high feature importace?"
      ],
      "metadata": {
        "id": "FJD6k16Af4NE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 13 answer:**"
      ],
      "metadata": {
        "id": "5R7iFqf3o_AB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Question 14**\n",
        "Now that you have experimented with two machine learning models, which model would you consider using for data analysis that is of your interest in your job or school projects?"
      ],
      "metadata": {
        "id": "eHuvB06jpMsi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 14 answer:**"
      ],
      "metadata": {
        "id": "hqjvD0bGpMs3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ™‚ Congratulations! You are learning a second machine learning model. You might feel more familiarized with the steps to follow to build machine learning models now, if not, don't worry there are other notebooks."
      ],
      "metadata": {
        "id": "1UsrBTAk5buA"
      }
    }
  ]
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pleunipennings/CSC508_ML_Biomedicine_Class/blob/main/Module2/Module_2b_Decision_Tree_Classifier_Overfitting_Cleveland_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7WqFNeW_z3y"
      },
      "source": [
        "## **Welcome to the module 2b coding part: Decision Tree Classifier and Overfitting!**\n",
        "\n",
        "*This notebook was originally created at San Francisco State University (SFSU) by Vaisakh Kusabhadran, Amisha Dhawan, Yuomi Zavaleta (all SFSU students) and Pleuni Pennings (SFSU bio professor).*\n",
        "\n",
        "*This notebook was edited for the Promoting INclusivity and Computing (PINC) and gSTAR programs by Dr. Pleuni Pennings, Lucy Moctezuma Tan and Lorena Benitez-Rivera (master students) all members of the COde to understand Drug resistance Evolution (CODE) lab at SFSU in 2023.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8C7-8DKKmCaK"
      },
      "source": [
        "#OBJECTIVE OF THIS NOTEBOOK:\n",
        "\n",
        "Now that we have learned how to make predictions using **Decision Trees**, we can take a look at what happens when we **overfit** or **underfit **our data.\n",
        "\n",
        "In this module we are going to continue using the 14 variables from the Cleveland dataset.\n",
        "\n",
        "Below we have a brief description of what each of the features we are going to use mean. The numbers next to the features are the ones that were used in the original dataset.\n",
        "\n",
        "<ul type = \"square\">\n",
        "<li> [1] #3 Age: age in years</li>\n",
        "<li> [2] #4 Sex: sex (1 = male; 0 = female)</li>\n",
        "<li> [3] #9 Chest_pain_type\n",
        "<ul>\n",
        "<li>Value 1: typical angina\n",
        "<li>Value 2: atypical angina\n",
        "<li>Value 3: non-anginal pain\n",
        "<li>Value 4: asymptomatic</li>\n",
        "</ul>\n",
        "<li> [4] #10 At_rest_bp: resting blood pressure (in mm Hg on admission to the hospital)</li>\n",
        "<li> [5] #12 Cholesterol: serum cholestoral in mg/dl </li>\n",
        "<li> [6] #16 Fast_blood_sug: (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false)</li>\n",
        "<li> [7] #19 Rest_ecg: resting electrocardiographic results\n",
        "<ul>\n",
        "<li>Value 0: normal\n",
        "<li>Value 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV)\n",
        "<li>Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria</li>\n",
        "</ul>\n",
        "<li> [8] #32 Maxhr: thalach: maximum heart rate achieved</li>\n",
        "<li> [9] #38 Exer_angina: exang: exercise induced angina (1 = yes; 0 = no)</li>\n",
        "<li> [10] #40 Oldpeak: ST depression induced by exercise relative to rest </li>\n",
        "<li> [11] #41 Slope: the slope of the peak exercise ST segment\n",
        "<ul>\n",
        "<li> Value 1: upsloping</li>\n",
        "<li> Value 2: flat</li>\n",
        "<li> Value 3: downsloping</li>\n",
        "</ul>\n",
        "<li> [12] #44 Ca: number of major vessels (0-3) colored by flourosopy</li>\n",
        "<li> [13] #51 Thal: Thallium or stress test 3 = normal; 6 = fixed defect; 7 = reversable defect. See this\n",
        "<a href=\"https://www.healthline.com/health/thallium-stress-test\">website</a>\n",
        "for more info on the thallium or stress test.\n",
        "</li>\n",
        "<li> [14] #58 Diag: num: diagnosis of heart disease (angiographic disease status)\n",
        "<ul>\n",
        "<li>Value 0: no vessel with 50% diameter narrowing</li>\n",
        "<li>Value 1: one vessel with 50% diameter narrowing</li>\n",
        "<li>Value 2,3,4: 2,3,4 vessels with 50% diameter narrowing</li>\n",
        "</ul>\n",
        "</li>\n",
        "</ul>\n",
        "\n",
        "The **goal** of this notebook is to learn how overfitting works using the decision tree classifier model. I like decision trees because they are easier to understand than most other machine learning or statistical learning methods.\n",
        "\n",
        "Your mission is to run each cell, see what happens, and answer some questions based on the code.\n",
        "\n",
        "# Let's look at the Cleveland dataset again with a focus on **overfitting**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VztpYoI9-950"
      },
      "source": [
        "#WHAT IS OVERFITTING?\n",
        "\n",
        "In machine learning it's important to train the models properly, not too much, not too little. For that reason, it's important to learn how to handle data that could be either overfitting or underfitting.\n",
        "\n",
        "![Underfitting_e_overfitting.png](\n",
        "https://upload.wikimedia.org/wikipedia/commons/d/d2/Underfitting_e_overfitting.png)\n",
        "\n",
        "**OVERFITTING**: is a undesirable machine learning behavior, where our model follows too closely our training data, meaning it learns to predict our training data very well but it fails to make accurate predictions for new data.\n",
        "\n",
        "**UNDERFITTING**: is a undesirable machine learning behavior, where our model\n",
        "does not get to learn enough from our training data, and therefore performs poorly when trying to make predictions for new data.\n",
        "\n",
        "What we actually want is somewhere in the middle, we want it to fit just right like a nice shoe! We dont want our shoes to be so loose that we could loose them while walking (underfit) or so perfectly close to the shape of our foot that it feels too tight to walk comfortably (overfit).\n",
        "\n",
        "You can find more information about overfitting and underfitting here: [Scikit-learn: Underfitting vs. Overfitting](https://scikit-learn.org/stable/auto_examples/model_selection/plot_underfitting_overfitting.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PR77ZeZ0_jcF"
      },
      "source": [
        "## **Step 1) Importing packages**\n",
        "\n",
        "Here we importing all the necessary packagesâ€“ we'll explain what they do later when we use them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ykwp-svEYtD"
      },
      "outputs": [],
      "source": [
        "# packages for data manipulation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# packages for creating the machine learning model\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn import tree\n",
        "\n",
        "# packages for plotting\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import graphviz\n",
        "\n",
        "#hyperparameter tuning imports\n",
        "from sklearn.model_selection import validation_curve"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmD5_IW8D_nR"
      },
      "source": [
        "##**Step 2) Importing Cleveland dataset**\n",
        "First, we fetch the dataset from the 508 class github repository and state what columns we are interested in. The data are stored in a pandas data frame called \"data\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YfNEx05xnAcK"
      },
      "outputs": [],
      "source": [
        "# Loading our dataset again from github\n",
        "columns = [\"Age\",\"Sex\",\"Chest_pain_type\",\"At_rest_bp\",\"Cholesterol\",\"Fast_blood_sug\",\"Rest_ecg\",\"Maxhr\",\"Exer_angina\",\"Oldpeak\",\"Slope\",\"Ca\",\"Thal\",\"Diag\"]\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/pleunipennings/CSC508Data/main/processed.cleveland.data.txt',header=None, names=columns)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLrZ0CFOAoD6"
      },
      "source": [
        "##**Step 3) Dealing with missing data**\n",
        "Next, we are going to do some work to deal with the missing data. Note that every dataset encodes **Missing values** differently, which is why it is a good idea sometimes to check exactly how missing values were encoded either from your data source, looking at the documentation about the data, etc.\n",
        "\n",
        "In this case our dataset missing values, were encoded with a **\"question mark (?)\"**. Identify the columns having missing values\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cImVL7v-FJAn"
      },
      "source": [
        "### **Task 1:** Checking for missing data (Questions 1-3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vW8GlfhJS_fu"
      },
      "source": [
        "### **Question 1:**\n",
        "\n",
        "Is there missing data in the dataset, if so, how can you check that?\n",
        "\n",
        "Which are the variables that have missing data?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYHItZEPTah7"
      },
      "source": [
        "**Question 1 answer:**\n",
        "column of CA and Thal has missing values. CA has 4 while Thal has 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuIfTBq8UO3d"
      },
      "source": [
        "### **Question 2:**\n",
        "\n",
        "How can you display the missing values location?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kifmuCEgUpjs"
      },
      "source": [
        "**Question 2 answer:**By locating the dataframe where the value is ? in the column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4fc7M3qLbd8"
      },
      "source": [
        "Dealing with missing data, by replacing all missing values with the medians of the feature column.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ciJjEafrHVb3"
      },
      "outputs": [],
      "source": [
        "# Replacing all the missing data with the median\n",
        "data = data.replace('?', np.nan)\n",
        "#====================================================#\n",
        "# Convert 'Thal' and 'Ca' columns to numeric before calculating the median\n",
        "data['Thal'] = pd.to_numeric(data['Thal'])\n",
        "data['Ca'] = pd.to_numeric(data['Ca'])\n",
        "#====================================================#\n",
        "data['Thal'] = data['Thal'].fillna(data['Thal'].median())\n",
        "data['Ca'] = data['Ca'].fillna(data['Ca'].median())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTIYQDLgI3oG"
      },
      "source": [
        "### **Question 3:**\n",
        "\n",
        "How can you verify that there is not missing values?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lXfyJ1V0JwDt"
      },
      "outputs": [],
      "source": [
        "#Code line to answer question 3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyDMfNCWCT2-"
      },
      "source": [
        "**Question 3 answer:**\n",
        "Use np.nan and sum them up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-kIkau_Lzwi"
      },
      "source": [
        "###**Task 2:** Understanding how machine learning models work (Questions 4-8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzMYdHxRo682"
      },
      "source": [
        "### **Question 4:**\n",
        "\n",
        "Write a list of the five basic steps there are before start training a machine learning model:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ztg-OHQTbWC"
      },
      "source": [
        "**Question 4 answer:**\n",
        "\n",
        "1.   list item\n",
        "2.   list item\n",
        "3.   list item\n",
        "4.   list item\n",
        "5.   list item\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0NmCQRT9l6x"
      },
      "source": [
        "## **Step 4)** **Splitting target and features**\n",
        "Next we will separate our target variable from our features (variables used for predictions).\n",
        "\n",
        "**NOTE:** We want to take the \"Diag\" column out of the features dataframe, because it is actually not a feature (in our analysis) but it is the \"target\"\n",
        "**Target** â€“ what we want to predict."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AIMYd1id4NCS"
      },
      "outputs": [],
      "source": [
        "# specifying target variable or label\n",
        "labels = np.array(data[\"Diag\"])\n",
        "\n",
        "#Specifying feature variables\n",
        "features = data.drop(columns='Diag')\n",
        "features = features.astype('float64')\n",
        "feats = np.array(features)\n",
        "\n",
        "# For brevity we will rename them as X(features) and y(label)\n",
        "X = features\n",
        "y = labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnoHyQOFvNNy"
      },
      "source": [
        "Next, we are converting the labels (stored in variable y) to binary values so that the model is trained just to predict the presence/absence of heart disease. All the values that are 1 or higher will just be 1 from here on. Recall that:\n",
        "\n",
        "- **[0]** means no vessel with 50% diameter narrowing (No Heart Disease)\n",
        "- **[1]** means one or more vessels with 50% diameter narrowing (Heart Disease)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XE0eZtynrvpq"
      },
      "outputs": [],
      "source": [
        "# converting our target variable into 1 and 0\n",
        "y = np.where(y >= 1,1,0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSAcrM0BdMNi"
      },
      "source": [
        "### **Question 5:**\n",
        "\n",
        "Why did we need to change the label to [0] no heart disease and [1] heart disease for this Decision Tree Classifier model dataset?\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwqewvBMZapj"
      },
      "source": [
        "**Question 5 answer:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ct6PZxP1Bk96"
      },
      "source": [
        "## **Step 5) Separating train and test data**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZfXuHyXuFKUn"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=2) # 70% training and 30% test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuYdf6Wpz81N"
      },
      "source": [
        "Up until now we have only reviewed what we have already done in the first part of the Notebook [Module 2a](https://colab.research.google.com/drive/1_c9LmAqNGwG2EBFSGCVpv5CzG6lOz29U?usp=share_link)\n",
        "\n",
        "Now we are going observe differences in fitting our tree when we change the **max_deph** argument."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNCNn4YvZh3C"
      },
      "source": [
        "### **Question 6:**\n",
        "\n",
        "Why do we use more percentage for training?\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWRmxVb6ZWMV"
      },
      "source": [
        "**Question 6 answer:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5_8uK48f9k3"
      },
      "source": [
        "### **Question 7:**\n",
        "\n",
        "Why do we use less percentage for testing?\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYugLvxsf_1L"
      },
      "source": [
        "**Question 7 answer:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGswTOTSYQEv"
      },
      "source": [
        "### **Question 8:**\n",
        "\n",
        "When we split the data into training and testing, does that mean that we start training from there, why or why not?\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSVXxthueP4V"
      },
      "source": [
        "**Question 8 answer:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7uUF2kthtnq"
      },
      "source": [
        "## **Step 6) Making the decision tree and making predictions with it**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MQXYqVVjz34"
      },
      "source": [
        "###**Task 3:** Testing underfitted and overfitted decision trees (Questions 9-12)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDtyO4uOrZid"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "#Underfitted Decision Tree\n",
        "\n",
        "Here we will create a Decision Tree that is only 2 layers deep. Just as before we will create it, train it and graph it. Later we will compare how our tree performs by making predictions for the training data as well as for the testing data.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4A3mvK8FMmR"
      },
      "outputs": [],
      "source": [
        "# Create Decision Tree classifer object\n",
        "clf_under = DecisionTreeClassifier(max_depth=2, random_state=2)\n",
        "\n",
        "# Train Decision Tree Classifer\n",
        "clf_under = clf_under.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vN1vK00w728l"
      },
      "source": [
        "Let's visualize our tree. Notice that because we specified that our tree should be at max 2 layers, the end gini values do not always reach to 0, unlike the first tree we made in the previous module, plus as expected we can see that there are only 2 layers 1 root node layer + 1 subsequent layer, before reaching the leaf nodes (prediction nodes). One layer, consists in all the nodes that are at the same height or level. For example: 2nd layer is composed of 2 nodes: ($Ca \\le 0.5$) and ($Chest \\ pain \\ type \\le 3.5$)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9n9rp0imFRBs"
      },
      "outputs": [],
      "source": [
        "# Code to visualize our Decision Tree\n",
        "dot_data_under = tree.export_graphviz(clf_under, out_file=None,\n",
        "                                  feature_names=features.columns,\n",
        "                                  filled=True, rounded=True,\n",
        "                                  special_characters=True)\n",
        "graph = graphviz.Source(dot_data_under)\n",
        "graph.render(\"Classification tree\")\n",
        "display(graph)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKUuRbUDAN0i"
      },
      "source": [
        " **a) Calculating Accuracy of Tree for training data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WAb0zv6CAOIA"
      },
      "outputs": [],
      "source": [
        "#Predict the response for training dataset\n",
        "y_pred_train = clf_under.predict(X_train)\n",
        "\n",
        "# Calculating Accuracy of our Tree\n",
        "acc_under_train = round(100 * metrics.accuracy_score(y_train, y_pred_train),2)\n",
        "print(\"Training Accuracy:\",acc_under_train,\"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gj4DMgnVoRod"
      },
      "source": [
        "### **Question 9:**\n",
        "\n",
        "What is the training accuracy %?\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zh_AdW3DoRox"
      },
      "source": [
        "**Question 9 answer:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yklEwwrj_RLi"
      },
      "source": [
        " **b) Calculating Accuracy of Tree for testing data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTOOS26d_NXk"
      },
      "outputs": [],
      "source": [
        "#Predict the response for test dataset\n",
        "y_pred = clf_under.predict(X_test)\n",
        "\n",
        "# Calculating Accuracy of our Tree\n",
        "acc_under_test = round(100 * metrics.accuracy_score(y_test, y_pred),2)\n",
        "print(\"Test Accuracy:\",acc_under_test,\"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2q0bT5BojYF"
      },
      "source": [
        "### **Question 10:**\n",
        "\n",
        "What is the testing accuracy %?\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upOsBwzzojYO"
      },
      "source": [
        "**Question 10 answer:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIQ-YC1DCT1b"
      },
      "source": [
        "As we can see, our model is not great at predicting the training data nor the testing data. This is a case of **underfitting**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QBnXOQ_6e-3"
      },
      "source": [
        "#Overfitted Decision Tree\n",
        "\n",
        "Here we will create a Decision Tree that is only 10 layers deep. Just as before we will train it, and then use our test data to make predictions to check our accuracy of our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwamao4_xdvM"
      },
      "outputs": [],
      "source": [
        "# Create Decision Tree classifer object\n",
        "clf_over = DecisionTreeClassifier(max_depth=10, random_state=2)\n",
        "\n",
        "# Train Decision Tree Classifer\n",
        "clf_over = clf_over.fit(X_train,y_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2rJ9ogpDRGZ"
      },
      "source": [
        "Below we will graph our tree as before. This time note that the gini values for our tree do reach to 0, unlike the underfitted Decision tree. When we do not specify the depth of our created tree, the default is to run our tree until it reaches a gini value of 0. But we will see that this doesn't always mean that we have the most optimal model. What we actually care about is having a high accuracy when predicting TESTING Data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORZEDAexDmQL"
      },
      "outputs": [],
      "source": [
        "# Code to visualize our Decision Tree\n",
        "dot_data_over = tree.export_graphviz(clf_over, out_file=None,\n",
        "                                  feature_names=features.columns,\n",
        "                                  filled=True, rounded=True,\n",
        "                                  special_characters=True)\n",
        "graph2 = graphviz.Source(dot_data_over)\n",
        "graph2.render(\"Classification tree\")\n",
        "display(graph2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uddSqH51ESYY"
      },
      "source": [
        " **a) Calculating Accuracy of Tree for training data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQVtx1rYEWxd"
      },
      "outputs": [],
      "source": [
        "#Predict the response for training dataset\n",
        "y_pred_train2 = clf_over.predict(X_train)\n",
        "\n",
        "# Calculating Accuracy of our Tree\n",
        "acc_over_train = round(100 * metrics.accuracy_score(y_train, y_pred_train2),2)\n",
        "print(\"Training Accuracy:\",acc_over_train,\"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTdA6ykeor0g"
      },
      "source": [
        "### **Question 11:**\n",
        "\n",
        "What is the training accuracy %?\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKB86PySor02"
      },
      "source": [
        "**Question 11 answer:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mYindEZEsjy"
      },
      "source": [
        " **b) Calculating Accuracy of Tree for testing data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-883xAPgu8zw"
      },
      "outputs": [],
      "source": [
        "#Predict the response for test dataset\n",
        "y_pred2 = clf_over.predict(X_test)\n",
        "\n",
        "# Calculating Accuracy of our Tree\n",
        "acc_over_test = round(100 * metrics.accuracy_score(y_test, y_pred2),2)\n",
        "print(\"Test Accuracy:\",acc_over_test,\"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPji1VbXpbup"
      },
      "source": [
        "### **Question 12:**\n",
        "\n",
        "What is the training accuracy %?\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nd9wddHppbuv"
      },
      "source": [
        "**Question 12 answer:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2M8qQkVxE7Fb"
      },
      "source": [
        "As we can see, our model is amazing at predicting the training data, however the accuracy for the testing data is not great. This is a case of **overfitting**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k180r3bnkW98"
      },
      "source": [
        "###**Task 4:** Final thoughts (Questions 13-15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0Su5b-xHrrB"
      },
      "source": [
        "# Finding the Best Fitting Tree\n",
        "\n",
        "There are different methods to find the best fitting Decision Tree, the task of finding the best fitting Machine Learning Model in general is called **Hyper parameter tuning**. Each kind of machine learning model has different kinds of hyperparameters to tune. We will comeback to this concept in later modules. But for our example, we are trying to tune the **max_depth** of our Decision Tree Classifier. So how do we know what number to pick for max_depth?\n",
        "\n",
        "### Validation Curve\n",
        "One possibility would be to use a **validation curve**. In this method we essentially fit our tree using a range of depths. We saw in the previous part that choosing 2 produced underfitting and choosing 10 was overfitting, thus the optimal depth must be in between. So why don't we test a range from 1 to 10?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4N2eMafkJ8J4"
      },
      "outputs": [],
      "source": [
        "# Setting figure size\n",
        "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
        "\n",
        "# Choosing a range from 1 to 10 to test\n",
        "tree_depths = range(1,11)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vg0KcW0NZQP"
      },
      "source": [
        "Once we have the range of hyperparameter values we want to test (e.g., the depth of a decision tree), we can start plotting the validation curve.\n",
        "\n",
        "To create this plot, we use only the training+validation portion of our dataset, not the test data (since including it would cause data leakage). The data is split into multiple parts, called folds (by default, 5 folds), and during the cross-validation process, each fold is used once as the validation data while the remaining folds are used for training.\n",
        "\n",
        "While validation data is similar to testing data in that it is not used during training, it still comes from the same dataset, so it is not truly independent. By iterating through these folds, we can get a better idea of how the hyperparameter (e.g., tree depth) affects the model's performance, even though it is not entirely unbiased. This approach helps simulate \"unseen data\" scenarios for evaluation, but the test set should still be kept separate for final performance assessment.\n",
        "\n",
        "\n",
        "We call this k-fold cross-validation, here k=5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Zq5Wo7nNZkB"
      },
      "outputs": [],
      "source": [
        "# create validation curve\n",
        "train_scores, test_scores = validation_curve(\n",
        "    DecisionTreeClassifier(random_state=2),\n",
        "    X,\n",
        "    y,\n",
        "    param_name=\"max_depth\",\n",
        "    param_range=tree_depths,\n",
        "    scoring=\"accuracy\")\n",
        "\n",
        "# storing scores mean scores(from default 5 random splits)\n",
        "train_scores_mean = np.mean(train_scores, axis=1)\n",
        "validation_scores_mean = np.mean(test_scores, axis=1)\n",
        "\n",
        "# plot titles and labels\n",
        "plt.title(\"Validation Curve with Decision Tree Classifier\")\n",
        "plt.xlabel(r\"$\\max \\ depth$\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.ylim(0.0, 1.1)\n",
        "plt.plot(tree_depths, train_scores_mean, label=\"Training score\", color=\"darkorange\", lw=2)\n",
        "plt.plot(tree_depths, validation_scores_mean, label=\"Cross-validation score\", color=\"navy\", lw=2)\n",
        "\n",
        "# plot legend\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUKP5NK0rsEg"
      },
      "source": [
        "### **Question 13:**\n",
        "\n",
        "Can you tell which max depth is underfitting and overfitting just by looking at this graph? Explain how.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7n73kyersE9"
      },
      "source": [
        "**Question 13 answer:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvkEycGmSAbV"
      },
      "source": [
        "Below let's try using max_depth = 3 and see what results we get in our Decision Tree Classifier. Remember that what our ideal is to have high training and testing accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKiPHcv4UOY4"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=2)\n",
        "\n",
        "# Create Decision Tree classifer object\n",
        "clf_best = DecisionTreeClassifier(max_depth=3, random_state=2)\n",
        "\n",
        "# Train Decision Tree Classifer\n",
        "clf_best = clf_best.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJ4s6z0RbsTi"
      },
      "source": [
        " **a) Calculating Accuracy of Tree for training data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yRaoYRFLWsgN"
      },
      "outputs": [],
      "source": [
        "#Predict the response for training dataset\n",
        "y_pred_train3 = clf_best.predict(X_train)\n",
        "\n",
        "# Calculating Accuracy of our Tree\n",
        "acc_best_train = round(100 * metrics.accuracy_score(y_train, y_pred_train3),2)\n",
        "print(\"Training Accuracy:\",acc_best_train,\"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gu4sFS68btoT"
      },
      "source": [
        " **b) Calculating Accuracy of Tree for testing data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fVHhFy3nWtsV"
      },
      "outputs": [],
      "source": [
        "#Predict the response for test dataset\n",
        "y_pred_best = clf_best.predict(X_test)\n",
        "\n",
        "# Calculating Accuracy of our Tree\n",
        "acc_best_test = round(100 * metrics.accuracy_score(y_test, y_pred_best),2)\n",
        "print(\"Test Accuracy:\",acc_best_test,\"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGTD_yxlYoTB"
      },
      "source": [
        "As we can see we have bumped our testing accuracy from low 70's% in both cases of (underfitting and overfitting) to 80.22% with the help of our cross validation curve!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIOk5RoCtSZ-"
      },
      "source": [
        "###**Question 14:**\n",
        "\n",
        "Did you find this module understandable or do you believe it requires more details and explanation?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apBTrPKMtSaR"
      },
      "source": [
        "**Question 14 answer:**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9-jyFVJ496R"
      },
      "source": [
        "###**Question 15:**\n",
        "\n",
        "Write down one thing you learned today and one thing that confuses you. (I know, I ask this all the time, but it is important to think about it for a few seconds!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6NQTlguO6GC"
      },
      "source": [
        "**Question 15 answer:**\n",
        "\n",
        "Learned\n",
        "1.   \n",
        "\n",
        "\n",
        "Confused   \n",
        "2.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UsrBTAk5buA"
      },
      "source": [
        "# ðŸ™‚ Congratulations! You just finished working on the first machine learning model Decision Trees. You should be proud of how much you have learned (even if you feel like some of this is still confusing, it's going to get easier with practice)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
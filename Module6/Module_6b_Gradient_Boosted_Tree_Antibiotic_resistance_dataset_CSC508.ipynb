{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pleunipennings/CSC508_ML_Biomedicine_Class/blob/main/Module6/Module_6b_Gradient_Boosted_Tree_Antibiotic_resistance_dataset_CSC508.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jr_YDcEQgNX"
      },
      "source": [
        "##**Welcome to the module 6b coding part: Grading Boosted Tree!**\n",
        "\n",
        "*This notebook was created at San Francisco State University (SFSU) for the Promoting INclusivity and Computing (PINC) and gSTAR programs by Dr. Pleuni Pennings (SFSU biology professor), Lucy Moctezuma Tan (California State University, East Bay CSUEB master student) and Lorena Benitez-Rivera (SFSU master students). All members of the COde to understand Drug resistance Evolution (CODE) lab in 2023.*"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#OBJECTIVE OF THIS NOTEBOOK:\n",
        "\n",
        "In this notebook we will learn how to create a **Gradient Boosted Tree** model using different functions that will allow us to get predicted labels for each type of drug instead of doing it one drug at a time.\n",
        "\n",
        "The objective of this notebook is to learn how to apply what we have been learning in a more complex project, so you can think of different ways in which machine learning could be used. In this case we will try to recreate specifically some of the results from the **Gradient Boosted Tree** model that was used in [Moragadivand's 2018 paper](https://doi.org/10.1371/journal.pcbi.1006258).\n",
        "\n",
        "In this notebook you will learn:\n",
        "\n",
        "- How to create different functions that will let us run our **Gradient Boosted Tree** model per drug and per feature combinations.\n",
        "- How to link all functions together to create a cohesive workflow and get our results.    "
      ],
      "metadata": {
        "id": "4s_KUXfGSthq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 1) Importing packages needed**\n",
        "Just like before we will be loading up the previous packages and functions we have seen so far."
      ],
      "metadata": {
        "id": "fnpxHzYUUJ_M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the scikit-learn version to ensure compatibility\n",
        "!pip install scikit-learn==1.5.2"
      ],
      "metadata": {
        "id": "klOFCQgcb9JG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDa820s0JSoJ"
      },
      "outputs": [],
      "source": [
        "# Data manipulation imports for ML\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Import packages for Gradient Boosted Tree model\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn import preprocessing\n",
        "\n",
        "# Imports for model evaluation\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# Imports for data visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Imports for file management\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 2) Loading CSV file and creating dataframes for each antibiotic**"
      ],
      "metadata": {
        "id": "1MTk8vozVJqi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **a) Loading CSV created from previous notebook (6a)**\n",
        "\n",
        "Let's first load our merged dataframe, created by notebook 6a, containing each feature and labels for all our drugs. The datataframe contains:\n",
        "\n",
        "1.   **Year features as a matrix**\n",
        "2.   **Population structure features**\n",
        "3.   **Presence and absence of specific genes**\n",
        "\n",
        "We will learn in the following steps how to select different combinations of these 3 features."
      ],
      "metadata": {
        "id": "QNuEJfKcVSLb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loads csv file as a dataframe\n",
        "filepath= '/content/drive/MyDrive/EColi_ML_CSV_files/'\n",
        "# reads csv file as a dataframe\n",
        "All_Drugs_df = pd.read_csv(filepath+\"EColi_Merged_dfs.csv\", na_values=\"NaN\")\n",
        "All_Drugs_df.head()"
      ],
      "metadata": {
        "id": "psqfFp_yVsmy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **b) Creating dataframes for each drug**\n",
        "\n",
        "Below we will be creating the function **makeDF**, this will allow us to create one dataframe for each antibiotic drug, by joining the labels of one group and the features corresponding to it."
      ],
      "metadata": {
        "id": "7R5n7AplVk-Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a list of antibiotic names\n",
        "drug_list = All_Drugs_df.iloc[:,1:13].columns\n",
        "drug_list"
      ],
      "metadata": {
        "id": "lLeCU30hD0Wk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a function that makes dataframes for each antibiotic and dropping NaN values\n",
        "def makeDF(drug):\n",
        "  df_list = [All_Drugs_df[[\"Isolate\",drug]],All_Drugs_df.iloc[:,13:]]\n",
        "  Drug_df = pd.concat(df_list, axis=1)\n",
        "  Drug_df = Drug_df.dropna()\n",
        "  return Drug_df"
      ],
      "metadata": {
        "id": "CL1DDOxXEXER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below we will demonstrate how **makeDF** works by creating a single dataframe using the the drug AMP that contains the labels for AMP and all the features we are interested in."
      ],
      "metadata": {
        "id": "4-ngI8Wqr3Zj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# implementing function using as example the drug AMP\n",
        "AMP_df = makeDF(\"AMP\")\n",
        "\n",
        "# looking at the shape of AMP dataframe\n",
        "print(\"AMP dataframe shape: \", AMP_df.shape)\n",
        "\n",
        "# looking at the first 5 rows of this dataframe\n",
        "AMP_df.head()"
      ],
      "metadata": {
        "id": "goNBMMQFJkJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 3) Separating each drug dataframe into sections**\n",
        "\n",
        "The dataframe will be separated into 4 sections:\n",
        "\n",
        "1.   **Training features**\n",
        "2.   **Training labels**\n",
        "3.   **Testing features**\n",
        "4.   **Testing labels**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NMKzeaqPojso"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **a) Creating testing and training datasets for each antibiotic drug**\n",
        "Below we will be creating the function **Split_train_test**, which will allow us to split the dataset of each of the dataframes created by our previous function, and store these splits into a single python dictionary. Then we will test this function by splitting only the dataframe we created before using the drug AMP."
      ],
      "metadata": {
        "id": "B2BblFQkce6s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separating each dataframe into Labels and Features\n",
        "def Split_train_test(Drug_df,drug):\n",
        "  Train_test_dic = {}\n",
        "  labels = Drug_df[drug]\n",
        "  features = Drug_df.drop(columns=[drug])\n",
        "  features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.33, random_state=42)\n",
        "\n",
        "  Train_test_dic['labels_train'] = labels_train\n",
        "  Train_test_dic['features_train'] = features_train\n",
        "  Train_test_dic['labels_test'] = labels_test\n",
        "  Train_test_dic['features_test'] = features_test\n",
        "\n",
        "  return Train_test_dic"
      ],
      "metadata": {
        "id": "iP4HEW4qBO7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 1:\n",
        "Below we implement the function we just created and accessed specifically the training features of the AMP dataset. Try accessing the other three key-value pairs of this dictionary, such as the features of the testing dataset.\n",
        "What do you think are some of the benefits of using a dictionary to store the different parts of the dataset?"
      ],
      "metadata": {
        "id": "zTH8SQ7wxt-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementing the function Split_train_test() for AMP example\n",
        "AMP_Train_test_dic = Split_train_test(AMP_df,\"AMP\")\n",
        "AMP_Train_test_dic[\"features_train\"]"
      ],
      "metadata": {
        "id": "0WHHOfUHsfrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Access the features testing of the dictionary"
      ],
      "metadata": {
        "id": "jIAIDshOybI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below you can also access all the Python dictionary elements we have created for this specific AMP dataset. Below I decided to print the shape for each of the data chunks we have split."
      ],
      "metadata": {
        "id": "76DCmBe2wJXV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the shape of each dataframe or series stored in the dictionary created for drug AMP\n",
        "print(\"AMP\")\n",
        "for k, df in AMP_Train_test_dic.items():\n",
        "  print(k, df.shape)"
      ],
      "metadata": {
        "id": "lVlTqUmEzphk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 4) Creating different combination of features before training**\n",
        "Below we will be creating the function **combo_feat**, which will allow us to choose what are the specific combinations we want to use to train our model. As you can see we have decided to test all the ones present in the **combo_list** list:\n",
        "\n",
        "*   S (Population Structure)\n",
        "*   GS (Gene Presence/Absence and Population Structure)\n",
        "*   GY (Gene Presence/Absence, Year)\n",
        "*   SY (Population Structure, Year)\n",
        "*   GYS (All- Gene Presence/Absence, Population Structure, Year)\n"
      ],
      "metadata": {
        "id": "2IyqN506dQn4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# making a list of combinations of data sources we would like to test in our ML models\n",
        "combo_list = ['G','S', 'SY', 'GS', 'GYS']\n",
        "\n",
        "# making a function that creates different feature combinations of the predictor features\n",
        "def combo_feat(features_df, drug, combo):\n",
        "\n",
        "  # creating Year column filters for features_df\n",
        "  year_filter = [col for col in features_df if col.startswith(\"Year\")]\n",
        "  year_feat = features_df[year_filter]\n",
        "\n",
        "  # creating Population structure column filters for features_df\n",
        "  pop_str_filter = [col for col in features_df if col.startswith(\"cutoff\")]\n",
        "  pop_struc_feat = features_df[pop_str_filter]\n",
        "\n",
        "  # creating Gene precence column filters for features_df\n",
        "  gene_presc_filter = [col for col in features_df.columns if col not in pop_str_filter and col not in year_filter and col != \"Isolate\"]\n",
        "  gene_presc_feat = features_df[gene_presc_filter]\n",
        "\n",
        "  if combo == 'G':\n",
        "    df_list = [features_df['Isolate'], gene_presc_feat]\n",
        "    G_feat_df = pd.concat(df_list, axis=1)\n",
        "    G_feat_df = G_feat_df.drop(columns=['Isolate'])\n",
        "    return G_feat_df\n",
        "\n",
        "  if combo == 'S':\n",
        "    df_list = [features_df['Isolate'], pop_struc_feat]\n",
        "    S_feat_df = pd.concat(df_list, axis=1)\n",
        "    S_feat_df = S_feat_df.drop(columns=['Isolate'])\n",
        "    return S_feat_df\n",
        "\n",
        "  if combo == 'GY':\n",
        "    df_list = [features_df['Isolate'], gene_presc_feat, year_feat]\n",
        "    GY_feat_df = pd.concat(df_list, axis=1)\n",
        "    GY_feat_df = GY_feat_df.drop(columns=['Isolate'])\n",
        "    return GY_feat_df\n",
        "\n",
        "  if combo== \"GS\":\n",
        "    df_list = [features_df['Isolate'], gene_presc_feat, pop_struc_feat]\n",
        "    GS_feat_df = pd.concat(df_list, axis=1)\n",
        "    GS_feat_df = GS_feat_df.drop(columns=['Isolate'])\n",
        "    return GS_feat_df\n",
        "\n",
        "  if combo == 'SY':\n",
        "    df_list = [features_df['Isolate'], pop_struc_feat, year_feat]\n",
        "    SY_feat_df = pd.concat(df_list, axis=1)\n",
        "    SY_feat_df = SY_feat_df.drop(columns=['Isolate'])\n",
        "    return SY_feat_df\n",
        "\n",
        "  if combo == 'GYS':\n",
        "    df_list = [features_df['Isolate'], gene_presc_feat, pop_struc_feat, year_feat]\n",
        "    GYS_feat_df = pd.concat(df_list, axis=1)\n",
        "    GYS_feat_df = GYS_feat_df.drop(columns=['Isolate'])\n",
        "    return GYS_feat_df\n"
      ],
      "metadata": {
        "id": "JmzbwQBxlylk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Following the example of working with a single drug AMP, we can see below that we can actually test and access a specific part of the dictionary we created in the previous step and also choose specifically what feature combination we are interested in training. In this case is **GS (Gene Presence and Absence and Population Structure)**"
      ],
      "metadata": {
        "id": "_PlMvQeKy5fe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementing combo_feat() function created for training data\n",
        "AMP_GS_train_df = combo_feat(AMP_Train_test_dic['features_train'],\"AMP\",\"GS\")\n",
        "\n",
        "# looking only at the feature column names for the combination for \"GS\" for drug \"AMP\" for training data\n",
        "AMP_GS_train_df.columns"
      ],
      "metadata": {
        "id": "Q9Dw-DD0YNmT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 5) Creating Gradient Boosted Trees model and training it per feature combination**\n",
        "\n",
        "Below we will create  another function called **run_GB** that will let us create and train our Gradient Boosted Tree, by assigning a training data (features, labels and what feature combination) we would like to train."
      ],
      "metadata": {
        "id": "ZVOKCEZNeHzB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating Gradient Boosted Trees model function\n",
        "def run_GB(feat_train_df, lab_train, drug, combo):\n",
        "  labels = lab_train\n",
        "  le = preprocessing.LabelEncoder()\n",
        "  le.fit(labels)\n",
        "  labels_t = le.transform(labels)\n",
        "  print(drug +\" Training combo: \"+ combo)\n",
        "  GB =  XGBClassifier(random_state = 42)\n",
        "  GB = GB.fit(feat_train_df, labels_t)\n",
        "  return GB"
      ],
      "metadata": {
        "id": "QbEP2WYkWPxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below we will test our function by:\n",
        "- Using the **training features** we specified in the previously **(step 4)**.\n",
        "- Getting our **training labels** from the python dictionary we created before **(step 3)**\n",
        "- Specifying the feature combination we want, in this example, **GS**."
      ],
      "metadata": {
        "id": "eIxqBtgI1MOJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# implementing run_GB() for specific drug feature combination dataframe\n",
        "GB_AMP_GS_model = run_GB(AMP_GS_train_df, AMP_Train_test_dic['labels_train'],\"AMP\",\"GS\")\n",
        "GB_AMP_GS_model"
      ],
      "metadata": {
        "id": "zwP1itj6s2zK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 6) Making predictions from Gradient Boosted Trees model**\n",
        "We will create here another function called **predict** to make our predictions using:\n",
        "- The model we trained on **(step 5)**\n",
        "- Choosing the test features chunks we made from **(step 3)**"
      ],
      "metadata": {
        "id": "1px3jn-Djn77"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzEGZrwHAZ3W"
      },
      "outputs": [],
      "source": [
        "# creating a function using the model created and trained and the feature combinations from testing data\n",
        "def predict(GB_combo_Model, features_test):\n",
        "  labels_pred = GB_combo_Model.predict(features_test)\n",
        "  return labels_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below we will be resusing our function **combo_feat** to specify that we want to use only specific features from out test dataset, because it has to be based on what our model was trained with. In this case we only want **GS combination**."
      ],
      "metadata": {
        "id": "6YwORpE-5u6w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementing combo_feat() function created for testing data\n",
        "AMP_GS_test_df = combo_feat(AMP_Train_test_dic['features_test'],\"AMP\",\"GS\")\n",
        "\n",
        "# looking only at the feature column names for the combination for \"GS\" for drug \"AMP\" for testing data\n",
        "AMP_GS_test_df.columns"
      ],
      "metadata": {
        "id": "Svu9-wcs-gbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally we will use our function with the correct model and correct testing dataset, where the only combination we want to make predictions with is GS. We will also print out how many did our model predict Resistance(R) and how many were predicted as Susceptible(S). In this case we got 210 Resistant E.Coli Predicted and 68 E.Coli Susceptible Predicted to the AMP drug, using only the feature combination GS.\n",
        "\n"
      ],
      "metadata": {
        "id": "Wm7xVv3k62Hy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementation of the predict() function using the feature combination \"GS\"\n",
        "AMP_GS_labels_pred = predict(GB_AMP_GS_model,AMP_GS_test_df)\n",
        "\n",
        "# transforming back our labels for interpretation in the next output\n",
        "labels_pred = np.where(AMP_GS_labels_pred<1,\"R\",\"S\")\n",
        "\n",
        "# observe how many predictions were made for each category \"R\" and \"S\"\n",
        "print(\"Labels predicted: \", np.unique(labels_pred, return_counts=True))"
      ],
      "metadata": {
        "id": "eP-xPTOwwL7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 7) Evaluating our model using a confusion matrix and metrics**\n",
        "\n",
        "Below we create our last function **evaluate**, where we are able to extract our accuracy and recall for Resistant and Susceptible E.Coli, plus a Confusion Matrix. Notice that within the function, we had to convert the labels test into numbers as well in order to be able to be compared with our predicted labels."
      ],
      "metadata": {
        "id": "5dox3JfFn5wz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a function that evaluates our model using our actual and predicted data\n",
        "def evaluate(GB_combo_model, labels_test, labels_pred, cf= True):\n",
        "  labels = labels_test\n",
        "  le = preprocessing.LabelEncoder()\n",
        "  le.fit(labels)\n",
        "  labels_t = le.transform(labels)\n",
        "  report = classification_report(labels_t, labels_pred, output_dict = True)\n",
        "  accuracy = report['accuracy']\n",
        "  R_recall = report[\"0\"]['recall']# Resistant\n",
        "  S_recall = report[\"1\"]['recall']# Susceptible\n",
        "  if cf == True:\n",
        "    labels_pred = np.where(labels_pred<1,\"R\",\"S\")\n",
        "    cm = confusion_matrix(labels_test, labels_pred, labels=np.where(GB_combo_model.classes_<1,\"R\",\"S\"))\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=np.where(GB_combo_model.classes_<1,\"R\",\"S\"))\n",
        "    disp.plot()\n",
        "    plt.show()\n",
        "  return [accuracy,R_recall,S_recall]"
      ],
      "metadata": {
        "id": "YJJmoOq-o97t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below we will be testing our function using:\n",
        "- The model we trained in **(step 5)**\n",
        "- The test labels we separated and put into a data dictionary in **(Step 3)**\n",
        "- The predicted labels that we got from **(Step 6)**"
      ],
      "metadata": {
        "id": "75jR4SguStUt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# implementing the evaluate() function\n",
        "Model_Report = evaluate(GB_AMP_GS_model, AMP_Train_test_dic['labels_test'],AMP_GS_labels_pred)\n",
        "print(\"Results from Model for drug: AMP\")\n",
        "print(\"Using feature combination: GS\")\n",
        "print(\"Accuracy: \", Model_Report[0])\n",
        "print(\"R_recall: \", Model_Report[1])\n",
        "print(\"S_recall: \", Model_Report[2])"
      ],
      "metadata": {
        "id": "J_qX1ZUl_oIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 2:\n",
        "As a review, list all the functions we have created so far in this notebook. Write a one-sentence description in your own words for each of the functions. We will use those functions in step 8."
      ],
      "metadata": {
        "id": "RSrzXaKWV8nD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 8) Use all functions and evaluate every drug in every feature combination!**\n",
        "\n",
        "Alright this is the part where we put all our created functions into use by creating a for loop, that chains each of the steps we have done so far.\n",
        "\n"
      ],
      "metadata": {
        "id": "N5lGr0hoDCip"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Complete Task 2 here**"
      ],
      "metadata": {
        "id": "tsw41MQnV_nw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **a) Lets recall the list of drugs we have available and the combination of features we are interested in**"
      ],
      "metadata": {
        "id": "yExXAdaWZL4_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# let's check all drugs\n",
        "drug_list"
      ],
      "metadata": {
        "id": "51wJM2XUaxtQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's see all combinations we are interested in\n",
        "combo_list"
      ],
      "metadata": {
        "id": "l-j7fp3eayEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **b) Create a loop that will go through all our functions using the lists above**\n",
        "\n",
        "Below is how we chose to chain these functions in order to get all our results and store them in a dictionary called **GB_model_metrics**. Note that this will take a long time as it is training for each drug every combination of features we have specified, so just sit back and grab something to drink as the computer does it's job.  You can check the print out to see what model it's currently training.\n",
        "\n",
        "**Note:** This loop will take some time to run. Lucy Moctezuma who wrote the code says it took 42 minutes when she last did it.\n",
        "If that is too long for you, feel free to focus on fewer of the drugs and fewer of the combintions. For example, you could loop over part of the drug_list (for drug in drug_list[:3]"
      ],
      "metadata": {
        "id": "cZWO1rYocRQR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets use all our functions this time and save our report into a single data structure\n",
        "GB_model_metrics = {}\n",
        "\n",
        "for drug in drug_list:\n",
        "  print(drug)\n",
        "  Drug_df = makeDF(drug) # creates one df per drug\n",
        "  Test_Train_dic = Split_train_test(Drug_df, drug) # splits each drug df into a dictionary with testing and training data\n",
        "  for combo in combo_list:\n",
        "    # Training each drug_combo features\n",
        "    labels_train = Test_Train_dic[\"labels_train\"]\n",
        "    features_train = combo_feat(Test_Train_dic[\"features_train\"], drug, combo) # create corresponding feature_df for training\n",
        "    GB_combo_model = run_GB(features_train, labels_train, drug, combo) # runs gradient boosted model using the corresponding training feature_df\n",
        "\n",
        "    # Predicting each drug_combo features\n",
        "    features_test = combo_feat(Test_Train_dic[\"features_test\"], drug, combo) # create corresponding feature_df for testing\n",
        "    labels_pred = predict(GB_combo_model, features_test) # generate predictions based on the feature combination tested\n",
        "\n",
        "    # Evaluating our models\n",
        "    labels_test = Test_Train_dic[\"labels_test\"]\n",
        "    report = evaluate(GB_combo_model, labels_test, labels_pred, cf=False) #extracting the metrics we want from the models report\n",
        "    GB_model_metrics[drug+\"_\"+combo] = report #saving these metrics into dictionary\n",
        "\n",
        "    print(report)"
      ],
      "metadata": {
        "id": "glSAeIj2DrnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **c) Store the metrics report for all drugs and features combinations as a csv file**\n",
        "\n",
        "After running our code is only necessary for us to save it as a csv file, that way we can access it later on!"
      ],
      "metadata": {
        "id": "m8CQMKARZ1zC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# convert dictionary into a dataframe\n",
        "GB_metrics = pd.DataFrame.from_dict(GB_model_metrics, orient='index',columns=[\"Accuracy\", \"R_recall\", \"S_recall\"]).reset_index()\n",
        "GB_metrics = GB_metrics.rename(columns = {'index':'Drug_combo'})\n",
        "\n",
        "# saving our metric results into a CSV file\n",
        "GB_metrics.to_csv(filepath+\"GB_metrics_df.csv\", index= False)\n",
        "GB_metrics\n"
      ],
      "metadata": {
        "id": "VmNdWS65fhRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **d) Create a bar graph showing accuracies of all drugs when using all features (GS)**\n",
        "\n",
        "Below we will create a quick bar graph checking at how each of the drugs performed using the specific combination of GS. (Gene Absence and Presence + Population Structure)"
      ],
      "metadata": {
        "id": "2-6NzvrsbZaH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# filtering for all the rows that contain GS combination only\n",
        "GS_filter = [drug_combo for drug_combo in GB_metrics['Drug_combo'] if drug_combo.endswith(\"GS\")]\n",
        "GS_df = GB_metrics.loc[GB_metrics[\"Drug_combo\"].isin(GS_filter)]\n"
      ],
      "metadata": {
        "id": "X408J96wZGD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting bar graph of only\n",
        "\n",
        "# Figure Size\n",
        "fig = plt.figure(figsize =(20, 8))\n",
        "\n",
        "# Adding title\n",
        "plt.title('Accuracy, R_recall and S_recall', fontsize = 12)\n",
        "\n",
        "# Variables to be plotted\n",
        "x = np.arange(len(GS_df[\"Drug_combo\"]))\n",
        "acc = list(GS_df[\"Accuracy\"])\n",
        "R_rec = list(GS_df[\"R_recall\"])\n",
        "S_rec = list(GS_df[\"S_recall\"])\n",
        "\n",
        "# Plotting barcharts\n",
        "acc_bar=plt.bar(x-0.25, height= acc, width=0.25, color=\"darkgrey\", edgecolor=\"gray\")\n",
        "r_rec_bar=plt.bar(x, height= R_rec, width=0.25, color=\"goldenrod\", align=\"center\", edgecolor=\"gray\")\n",
        "s_rec_bar=plt.bar(x+0.25, height= S_rec, width=0.25, color=\"palegoldenrod\", edgecolor=\"gray\")\n",
        "\n",
        "plt.xticks([r for r in range(len(GS_df[\"Drug_combo\"]))],\n",
        "        GS_df[\"Drug_combo\"], fontsize = 12)\n",
        "\n",
        "#legend\n",
        "fig.legend([acc_bar,r_rec_bar,s_rec_bar],[\"Accuracy\", \"R_recall\", \"S_recall\"], bbox_to_anchor=(0.4,-0.35, 0.04, 0.4), fontsize=12)\n",
        "\n",
        "# Show Plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ShYKLLRNkkZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 3:\n",
        "\n",
        "Looking at the Graph above and the barplots for percentage resistance you made in 6A, why do you think TZP had such a high accuracy but such low Resistance Recall Score?"
      ],
      "metadata": {
        "id": "w9jCQ9R2qaNf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer your question here**"
      ],
      "metadata": {
        "id": "_5PoigXdqwN1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 4. Optional here but will be required in Module 7:\n",
        "\n",
        "Now that you have seen how creating different functions and stringing them together allows you to tackle a more complex project, try to challenge yourself and do the same but using a Random Forest Model!\n",
        "- Feel free to use this code as a general guide, but remember there are many ways to tackle this problem!\n",
        "- Create your own functions and see if you can get as an end result to recreate the final dataframe and csv file with all the results stored.\n",
        "  - If you choose to do this challenge now, name this file \"**RF_metrics_df.csv**\" (like your GB_metrics_df.csv file created here)\n",
        "    - You will need to create the RF_metrics_df.csv file for Notebook 7b if you do not do it here."
      ],
      "metadata": {
        "id": "ij-hNMh7qzts"
      }
    }
  ]
}